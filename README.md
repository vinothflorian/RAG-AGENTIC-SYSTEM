# FedRAG: Retrieval-Augmented Generation System for the U.S. Federal Register

**FedRAG** is an intelligent, agentic RAG (Retrieval-Augmented Generation) system that enables users to ask questions about U.S. Federal Register documents and receive concise, AI-generated answers based on official government content.

This system uses:
- âœ… **MySQL** as a source of truth
- âœ… **Ollama + Qwen2.5 LLM** for local inference
- âœ… **Keyword-based SQL retrieval**
- âœ… **Summarization using local LLM**
- âœ… **Streamlit** for a user-friendly frontend
- âœ… **Asynchronous Python pipeline**

---

## ğŸ”§ Features

- ğŸ“¥ **Automated Data Pipeline**  
  Fetches JSON documents from the Federal Register and inserts them into a MySQL database.

- ğŸ§  **Local LLM Agent (Ollama + Qwen)**  
  Extracts relevant keywords and generates concise answers using locally hosted LLMs.

- ğŸ” **RAG System**  
  Retrieves top-matching rows using MySQL full-text search on extracted keywords.

- ğŸ“Š **Streamlit Interface**  
  A web-based UI where users can ask natural language questions.

- ğŸ§µ **Context Formatting**  
  Combines multiple matching rows into a coherent document for the LLM to summarize.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ data_pipeline/
â”‚   â”œâ”€â”€ downloader.py         # Downloads JSON data from official site
â”‚   â””â”€â”€ processor.py          # Inserts parsed data into MySQL
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ KEY_QUERY.py          # Keyword extractor using Ollama
â”‚   â”œâ”€â”€ SQL_FETCH.py          # SQL search logic using extracted keywords
â”‚   â””â”€â”€ LLM.py                # Main RAG logic (keyword â†’ search â†’ summarize)
â”‚
â”œâ”€â”€ streamlit_app.py          # Streamlit UI to interact with the system
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/fedrag.git
cd fedrag
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Set Up MySQL

Create a MySQL database named `federal_register` with a table:

```sql
CREATE TABLE federal_documents (
    document_number VARCHAR(255),
    title TEXT,
    publication_date DATE,
    html_url TEXT,
    abstract TEXT
);
```

Update your MySQL credentials in `processor.py` and `SQL_FETCH.py`.

### 4. Run Data Pipeline

```bash
python data_pipeline/downloader.py
python data_pipeline/processor.py
```

### 5. Start the Agent

```bash
python agent/LLM.py
```

Or run the UI:

```bash
streamlit run streamlit_app.py
```

---

## ğŸ“¦ Requirements

- Python 3.10+
- MySQL Server
- [Ollama](https://ollama.com) installed locally
- LLM model like `qwen:0.5b` pulled into Ollama

```bash
ollama pull qwen:0.5b
```

---

## ğŸ§  Sample Query

> **User:** "Show me proposals on illegal discrimination"  
> **System:** Extracts keywords â†’ retrieves matching documents â†’ summarizes them using the LLM â†’ displays the final answer

---

## âœ¨ Future Enhancements

- Add agent memory and history tracking
- Semantic search using vector embeddings
- Schedule automatic updates of database
- Enable document upload for private RAG

---

## ğŸ›¡ License

This project is open source and available under the [MIT License](LICENSE).

---

## ğŸ‘¨â€ğŸ’» Author

**Vinoth Zavier**  
For support or collaboration, feel free to connect.